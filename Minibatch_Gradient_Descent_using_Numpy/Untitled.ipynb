{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://wiseodd.github.io/techblog/2016/06/21/nn-sgd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 382 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = make_moons(n_samples=5000, random_state=42, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_feature = 2\n",
    "n_class = 2\n",
    "n_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_network(n_hidden=100):\n",
    "    # Initialize weights with Standard Normal random variables\n",
    "    model = dict(\n",
    "        W1=np.random.randn(n_feature, n_hidden), # Generate matrix(n_feature x n_hidden size)\n",
    "        W2=np.random.randn(n_hidden, n_class)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(x, model):\n",
    "    # Input to hidden\n",
    "    h = x @ model['W1'] # @: Matrix Multiplication \n",
    "    # ReLU non-linearity\n",
    "    h[h < 0] = 0\n",
    "\n",
    "    # Hidden to output\n",
    "    prob = softmax(h @ model['W2'])\n",
    "\n",
    "    return h, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward(model, xs, hs, errs):\n",
    "    \"\"\"xs, hs, errs contain all informations (input, hidden state, error) of all data in the minibatch\"\"\"\n",
    "    # errs is the gradients of output layer for the minibatch\n",
    "    dW2 = hs.T @ errs\n",
    "\n",
    "    # Get gradient of hidden layer\n",
    "    dh = errs @ model['W2'].T\n",
    "    dh[hs <= 0] = 0\n",
    "\n",
    "    dW1 = xs.T @ dh\n",
    "\n",
    "    return dict(W1=dW1, W2=dW2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(model, X_train, y_train, minibatch_size):\n",
    "    for iter in range(n_iter):\n",
    "        print('Iteration {}'.format(iter))\n",
    "\n",
    "        # Randomize data point\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "        for i in range(0, X_train.shape[0], minibatch_size):\n",
    "            # Get pair of (X, y) of the current minibatch/chunk\n",
    "            X_train_mini = X_train[i:i + minibatch_size]\n",
    "            y_train_mini = y_train[i:i + minibatch_size]\n",
    "\n",
    "            model = sgd_step(model, X_train_mini, y_train_mini)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_step(model, X_train, y_train):\n",
    "    grad = get_minibatch_grad(model, X_train, y_train)\n",
    "    model = model.copy()\n",
    "\n",
    "    # Update every parameters in our networks (W1 and W2) using their gradients\n",
    "    for layer in grad:\n",
    "        # Learning rate: 1e-4\n",
    "        model[layer] += 1e-4 * grad[layer]\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch_grad(model, X_train, y_train):\n",
    "    xs, hs, errs = [], [], []\n",
    "\n",
    "    for x, cls_idx in zip(X_train, y_train):\n",
    "        h, y_pred = forward(x, model)\n",
    "\n",
    "        # Create probability distribution of true label\n",
    "        y_true = np.zeros(n_class)\n",
    "        y_true[int(cls_idx)] = 1.\n",
    "\n",
    "        # Compute the gradient of output layer\n",
    "        err = y_true - y_pred\n",
    "\n",
    "        # Accumulate the informations of minibatch\n",
    "        # x: input\n",
    "        # h: hidden state\n",
    "        # err: gradient of output layer\n",
    "        xs.append(x)\n",
    "        hs.append(h)\n",
    "        errs.append(err)\n",
    "\n",
    "    # Backprop using the informations we get from the current minibatch\n",
    "    return backward(model, np.array(xs), np.array(hs), np.array(errs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shuffle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bac3bbb0c3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e8262b7871db>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(model, X_train, y_train, minibatch_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[1;31m# Randomize data point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shuffle' is not defined"
     ]
    }
   ],
   "source": [
    "minibatch_size = 50\n",
    "n_experiment = 100\n",
    "\n",
    "# Create placeholder to accumulate prediction accuracy\n",
    "accs = np.zeros(n_experiment)\n",
    "\n",
    "for k in range(n_experiment):\n",
    "    # Reset model\n",
    "    model = make_network()\n",
    "\n",
    "    # Train the model\n",
    "    model = sgd(model, X_train, y_train, minibatch_size)\n",
    "\n",
    "    y_pred = np.zeros_like(y_test)\n",
    "\n",
    "    for i, x in enumerate(X_test):\n",
    "        # Predict the distribution of label\n",
    "        _, prob = forward(x, model)\n",
    "        # Get label by picking the most probable one\n",
    "        y = np.argmax(prob)\n",
    "        y_pred[i] = y\n",
    "\n",
    "    # Compare the predictions with the true labels and take the percentage\n",
    "    accs[k] = (y_pred == y_test).sum() / y_test.size\n",
    "\n",
    "print('Mean accuracy: {}, std: {}'.format(accs.mean(), accs.std()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
